{"version":3,"sources":["App.tsx","reportWebVitals.ts","index.tsx"],"names":["flattenQueue","queue","frameSize","length","freqData","Float32Array","forEach","data","i","set","getInputTensorFromFrequencyData","shape","vals","tf","sizeFromShape","EPSILON","normalize","x","epsilon","mean","variance","FREQUENCY_BINS","SPEECH_THRESHOLD","App","state","isRecording","patchInfos","interval","stopVad","setState","clearInterval","startVad","a","model","summary","audioContext","AudioContext","navigator","mediaDevices","getUserMedia","audio","video","audioStream","streamSource","createMediaStreamSource","analyser","createAnalyser","fftSize","smoothingTimeConstant","connect","frame","frequencyBinCount","frames","onAudioFrame","getFloatFrequencyData","Infinity","push","slice","console","log","freqDataTensor","normalizedX","result","predict","res","prediction","patchInfo","isSpeech","confidence","setInterval","bind","className","Header","as","this","Button","size","color","onClick","Icon","name","Container","style","border","padding","Grid","map","Column","Math","round","React","Component","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"ubAOMA,EAAe,SAACC,GAClB,IAAMC,EAAYD,EAAM,GAAGE,OACrBC,EAAW,IAAIC,aAAaJ,EAAME,OAASD,GAEjD,OADAD,EAAMK,SAAQ,SAACC,EAAMC,GAAP,OAAaJ,EAASK,IAAIF,EAAMC,EAAIN,MAC3CE,GAELM,EAAkC,SAACN,EAAwBO,GAC7D,IAAMC,EAAO,IAAIP,aAAaQ,IAAQC,cAAcH,IAGpD,OADAC,EAAKH,IAAIL,EAAUQ,EAAKT,OAASC,EAASD,QACnCU,IAAUD,EAAMD,IAGvBI,EAAyB,KACvBC,EAAY,SAACC,GAIf,OAHe,MAAXF,IACAA,EAAUF,MAAaK,WAEpBL,KAAQ,WAAO,IAAD,EACQA,IAAWI,GAA7BE,EADU,EACVA,KAAMC,EADI,EACJA,SAEb,OAAOP,IAAOA,IAAOI,EAAGE,GAAON,IAAOA,IAAQO,GAAWL,QAK3DM,EAAiB,IACjBC,EAAmB,UAqHVC,E,4MAvGXC,MAAkB,CACdC,aAAa,EACbC,WAAY,I,EAEhBC,c,IA0CAC,QAAU,WACN,EAAKC,SAAS,CACVJ,aAAa,IAEb,EAAKE,UACLG,cAAc,EAAKH,W,EAG3BI,S,sBAAW,0CAAAC,EAAA,6DACP,EAAKH,SAAS,CACVJ,aAAa,IAFV,SAIaZ,IAAmB,oBAJhC,cAIDoB,EAJC,QAKDC,UACAC,EAAe,IAAIC,aANlB,SAQgCC,UAAUC,aAAaC,aAAa,CAACC,OAAO,EAAMC,OAAO,IARzF,OAQDC,EARC,OASDC,EAAeR,EAAaS,wBAAwBF,IAEpDG,EAAWV,EAAaW,kBACrBC,QAAU,KACnBF,EAASG,sBAAwB,EACjCL,EAAaM,QAAQJ,GACfK,EAAQ,IAAI7C,aAAawC,EAASM,mBAClCC,EAAyB,GACzBC,EAjBC,+BAAArB,EAAA,MAiBc,wCAAAA,EAAA,yDACjBa,EAASS,sBAAsBJ,GAC3BA,EAAM,MAAQK,KACdH,EAAOI,KAAKN,EAAMO,MAAM,EAAGpC,IA1FnB,KA4FR+B,EAAOjD,OALM,wBAMbuD,QAAQC,IAAI,mBACNvD,EAAWJ,EAAaoD,GACxBQ,EAAiBlD,EACnBN,EAAU,CAAC,EAhGP,GAgG2BiB,EAAgB,IAC7CwC,EAAc7C,EAAU4C,GACxBE,EAAS7B,EAAM8B,QAAQF,GAXhB,UAYmBC,EAAOvD,OAZ1B,QAYPyD,EAZO,OAaPC,EAAaD,EAAI,GAEjBE,EAAY,CAACC,SADFF,EAAa3C,EACD8C,WAAYJ,EAAI,IAC7C,EAAKnC,UAAS,SAAAL,GAAK,MAAK,CACpBE,WAAW,GAAD,mBAAMF,EAAME,YAAZ,CAAwBwC,QAEtCR,QAAQC,IAAIO,GACZrD,IAAW,CAAC+C,EAAgBC,EAAaC,IACzCV,EAAOjD,OAAS,EArBH,4CAjBd,qDA2Ce,OAAgB,MACtC,EAAKwB,SAAW0C,YAAYhB,EAAaiB,KAAb,gBADN,oBA3Cf,4C,4CAhDX,WACI,OACI,sBAAKC,UAAU,MAAf,UACI,sBACA,cAACC,EAAA,EAAD,CAAQC,GAAG,KAAX,6BACCC,KAAKlD,MAAMC,YACR,eAACkD,EAAA,EAAD,CAAQC,KAAK,MAAMC,MAAM,MAAMC,QAASJ,KAAK9C,QAA7C,UACI,cAACmD,EAAA,EAAD,CAAMC,KAAK,SADf,UAKA,eAACL,EAAA,EAAD,CAAQC,KAAK,MAAMC,MAAM,MAAMC,QAASJ,KAAK3C,SAA7C,UACI,cAACgD,EAAA,EAAD,CAAMC,KAAK,eADf,4BAIJ,sBACCN,KAAKlD,MAAME,WAAWvB,OAAS,GAChC,cAAC8E,EAAA,EAAD,CAAWC,MAAO,CAACC,OAAQ,YAAaC,QAAS,OAAjD,SACI,cAACC,EAAA,EAAD,UAEQX,KAAKlD,MAAME,WAAW4D,KAAI,SAACpB,EAAW1D,GAAZ,OACtB,eAAC6E,EAAA,EAAKE,OAAN,WACKrB,EAAUC,SAAW,cAACY,EAAA,EAAD,CAAMH,KAAK,MAAMI,KAAK,OAAOH,MAAM,SACrD,cAACE,EAAA,EAAD,CAAMH,KAAK,MAAMI,KAAK,oBAC1B,8BACKQ,KAAKC,MAAM,IAAMvB,EAAUE,YADhC,SAHc5D,iB,GA5BhCkF,IAAMC,WCjCTC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCHdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.8ceb5a68.chunk.js","sourcesContent":["import React from 'react';\nimport './App.css';\nimport 'semantic-ui-css/semantic.min.css'\nimport {Button, Container, Grid, Header, Icon, Progress, Segment} from 'semantic-ui-react'\nimport * as tf from '@tensorflow/tfjs';\nimport {Tensor} from \"@tensorflow/tfjs-core\";\n\nconst flattenQueue = (queue: Float32Array[]): Float32Array => {\n    const frameSize = queue[0].length;\n    const freqData = new Float32Array(queue.length * frameSize);\n    queue.forEach((data, i) => freqData.set(data, i * frameSize));\n    return freqData;\n}\nconst getInputTensorFromFrequencyData = (freqData: Float32Array, shape: number[]): tf.Tensor => {\n    const vals = new Float32Array(tf.util.sizeFromShape(shape));\n    // If the data is less than the output shape, the rest is padded with zeros.\n    vals.set(freqData, vals.length - freqData.length);\n    return tf.tensor(vals, shape);\n}\n\nlet EPSILON: number | null = null;\nconst normalize = (x: tf.Tensor): tf.Tensor => {\n    if (EPSILON == null) {\n        EPSILON = tf.backend().epsilon();\n    }\n    return tf.tidy(() => {\n        const {mean, variance} = tf.moments(x);\n        // Add an EPSILON to the denominator to prevent division-by-zero.\n        return tf.div(tf.sub(x, mean), tf.add(tf.sqrt(variance), EPSILON!));\n    });\n}\n\nconst FRAMES_IN_PATCH = 43\nconst FREQUENCY_BINS = 232\nconst SPEECH_THRESHOLD = 0.32857817\n\n\ntype AppState = {\n    isRecording: boolean\n    patchInfos: PatchInfo[]\n}\n\ninterface PatchInfo {\n    isSpeech: boolean\n    confidence: number\n}\n\nclass App extends React.Component<{}, AppState> {\n    state: AppState = {\n        isRecording: false,\n        patchInfos: []\n    }\n    interval?: NodeJS.Timeout;\n\n    render() {\n        return (\n            <div className=\"App\">\n                <p/>\n                <Header as='h1'>VAD the Impaler</Header>\n                {this.state.isRecording ?\n                    <Button size='big' color='red' onClick={this.stopVad}>\n                        <Icon name='stop'/>\n                        Stop\n                    </Button>\n                    :\n                    <Button size='big' color='red' onClick={this.startVad}>\n                        <Icon name='microphone'/>\n                        Start Detecting Speech\n                    </Button>}\n                <p/>\n                {this.state.patchInfos.length > 0 &&\n                <Container style={{border: \"1px solid\", padding: \"5px\"}}>\n                    <Grid>\n                        {\n                            this.state.patchInfos.map((patchInfo, i) =>\n                                <Grid.Column key={i}>\n                                    {patchInfo.isSpeech ? <Icon size='big' name='chat' color='teal'/> :\n                                        <Icon size='big' name='window minimize'/>}\n                                    <p>\n                                        {Math.round(100 * patchInfo.confidence)}%\n                                    </p>\n                                </Grid.Column>\n                            )\n                        }\n                    </Grid>\n                </Container>\n                }\n            </div>\n        );\n    }\n\n    // <Progress size='small' percent={Math.round(100 * patchInfo.confidence)}\n    //           color={patchInfo.isSpeech ? 'teal' : \"grey\"} progress/>\n    //\n    stopVad = () => {\n        this.setState({\n            isRecording: false,\n        });\n        if (this.interval)\n            clearInterval(this.interval)\n    }\n\n    startVad = async (): Promise<void> => {\n        this.setState({\n            isRecording: true,\n        });\n        const model = await tf.loadLayersModel('model/model.json');\n        model.summary();\n        const audioContext = new AudioContext();\n\n        const audioStream: MediaStream = await navigator.mediaDevices.getUserMedia({audio: true, video: false})\n        const streamSource = audioContext.createMediaStreamSource(audioStream);\n\n        const analyser = audioContext.createAnalyser();\n        analyser.fftSize = 2048\n        analyser.smoothingTimeConstant = 0.0;\n        streamSource.connect(analyser);\n        const frame = new Float32Array(analyser.frequencyBinCount)\n        const frames: Float32Array[] = []\n        const onAudioFrame = async () => {\n            analyser.getFloatFrequencyData(frame);\n            if (frame[0] !== -Infinity) {\n                frames.push(frame.slice(0, FREQUENCY_BINS))\n            }\n            if (frames.length === FRAMES_IN_PATCH) {\n                console.log(\"Patch collected\")\n                const freqData = flattenQueue(frames);\n                const freqDataTensor = getInputTensorFromFrequencyData(\n                    freqData, [1, FRAMES_IN_PATCH, FREQUENCY_BINS, 1]);\n                const normalizedX = normalize(freqDataTensor);\n                const result = model.predict(normalizedX) as Tensor;\n                const res: Float32Array = await result.data() as Float32Array;\n                const prediction = res[0];\n                const isSpeech = prediction > SPEECH_THRESHOLD\n                const patchInfo = {isSpeech, confidence: res[0]}\n                this.setState(state => ({\n                    patchInfos: [...state.patchInfos, patchInfo]\n                }))\n                console.log(patchInfo);\n                tf.dispose([freqDataTensor, normalizedX, result]);\n                frames.length = 0\n            }\n\n        }\n\n        const frameDuration = 1000.0 * 1024 / 44100;\n        this.interval = setInterval(onAudioFrame.bind(this), frameDuration);\n    }\n\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}